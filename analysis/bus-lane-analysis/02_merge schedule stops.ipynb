{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# 0 Housekeeping. Clear variable space\n",
    "########################################################################################################################\n",
    "from IPython import get_ipython  # run magic commands\n",
    "ipython = get_ipython()\n",
    "ipython.magic(\"reset -f\")\n",
    "ipython = get_ipython()\n",
    "#https://stackoverflow.com/questions/36572282/ipython-autoreload-magic-function-not-found\n",
    "ipython.magic(\"load_ext autoreload\")\n",
    "ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Section 1 Import Libraries and Set Global Parameters...\n"
     ]
    }
   ],
   "source": [
    "# 1 Import Libraries and Set Global Parameters\n",
    "########################################################################################################################\n",
    "# 1.1 Import Python Libraries\n",
    "############################################\n",
    "from datetime import datetime\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import shutil\n",
    "print(\"Run Section 1 Import Libraries and Set Global Parameters...\")\n",
    "begin_time = datetime.now()\n",
    "import os, sys, pandas as pd, geopandas as gpd\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")  # Stop Pandas warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Set Global Parameters\n",
    "############################################\n",
    "if os.getlogin() == \"WylieTimmerman\":\n",
    "    # Working Paths\n",
    "    path_working = r\"C:\\OD\\OneDrive - Foursquare ITP\\Projects\\WMATA_AVL\"\n",
    "    os.chdir(os.path.join(path_working))\n",
    "    sys.path.append(r\"C:\\OD\\OneDrive - Foursquare ITP\\Projects\\WMATA_AVL\")\n",
    "    path_sp = r\"C:\\Users\\WylieTimmerman\\Documents\\projects_local\\wmata_avl_local\"\n",
    "    path_source_data = os.path.join(path_sp,\"data\",\"00-raw\")\n",
    "    path_processed_data = os.path.join(path_sp, \"data\",\"02-processed\")\n",
    "elif os.getlogin() == \"abibeka\":\n",
    "    # Working Paths\n",
    "    path_working = r\"C:\\Users\\abibeka\\OneDrive - Kittelson & Associates, Inc\\Documents\\Github\\WMATA_AVL\"\n",
    "    os.chdir(os.path.join(path_working))\n",
    "    sys.path.append(path_working)\n",
    "    # Source data\n",
    "    path_source_data = r\"C:\\Users\\abibeka\\OneDrive - Kittelson & Associates, Inc\\Documents\\WMATA-AVL\\Data\"\n",
    "    # Processed data\n",
    "    path_processed_data = os.path.join(path_source_data, \"ProcessedData\")\n",
    "elif os.getlogin() == \"E043868\":\n",
    "    # Working Paths\n",
    "    path_working = r\"C:\\Users\\e043868\\OneDrive - WMATA\\R Projects\\WMATA_AVL\"\n",
    "    os.chdir(os.path.join(path_working))\n",
    "    sys.path.append(r\"C:\\Users\\e043868\\OneDrive - WMATA\\R Projects\\WMATA_AVL\")\n",
    "    path_source_data = r\"\\\\l-600730\\RawNavArchive\"\n",
    "    path_sp = r\"C:\\Users\\e043868\\Documents\\RawNav\"\n",
    "    path_processed_data = os.path.join(path_sp, \"data\", \"02-processed\")\n",
    "\n",
    "elif os.getlogin() == \"E048374\":\n",
    "    # Working Paths\n",
    "    path_working = r\"C:\\Users\\E048374\\OneDrive - WMATA\\rawnav_rachel_fork\\WMATA_AVL\"\n",
    "    os.chdir(os.path.join(path_working))\n",
    "    sys.path.append(r\"C:\\Users\\E048374\\OneDrive - WMATA\\rawnav_rachel_fork\\WMATA_AVL\")\n",
    "    path_source_data = r\"\\\\l-600730\\RawNavArchive\"\n",
    "    path_sp = r\"C:\\Users\\E048374\\Documents\\RawNav\"\n",
    "    path_processed_data = os.path.join(path_sp, \"data\", \"02-processed\")\n",
    "   \n",
    "    \n",
    "else:\n",
    "    raise FileNotFoundError(\"Define the path_working, path_source_data, and\"\n",
    "                            \" path_processed_data in a new elif block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "q_jump_route_list = ['52']\n",
    "analysis_routes = q_jump_route_list\n",
    "analysis_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "wmata_crs = 2248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Time Section 1 Import Libraries and Set Global Parameters : 0:00:08\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Import User-Defined Package\n",
    "############################################\n",
    "import wmatarawnav as wr\n",
    "\n",
    "executionTime = str(datetime.now() - begin_time).split('.')[0]\n",
    "print(\"Run Time Section 1 Import Libraries and Set Global Parameters : {}\".format(executionTime))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Section 2: Read, analyze and summarize rawnav, WMATA schedule data...\n",
      "****************************************************************************************************\n",
      "Processing analysis route 52\n",
      "Processing analysis route 52 for Monday...\n",
      "deleted 2 rows of 233 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 0 of 231 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Tuesday...\n",
      "deleted 4 rows of 306 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 0 of 302 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Wednesday...\n",
      "deleted 21 rows of 663 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 35 of 642 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Thursday...\n",
      "deleted 62 rows of 539 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 0 of 477 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Friday...\n",
      "deleted 76 rows of 1036 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 0 of 960 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Saturday...\n",
      "deleted 23 rows of 435 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 0 of 412 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Sunday...\n",
      "No data on analysis route 52 for Sunday\n",
      "Run Time Section Section 2: Read, analyze and summarize rawnav, WMATA schedule data : 0:00:10\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# 2 Read, analyze and summarize Schedule data\n",
    "########################################################################################################################\n",
    "print(\"Run Section 2: Read, analyze and summarize rawnav, WMATA schedule data...\")\n",
    "begin_time = datetime.now()\n",
    "# Read the Wmata_Schedule data\n",
    "wmata_schedule_dat = (\n",
    "    pd.read_csv(\n",
    "        os.path.join(path_sp, \"wmata_schedule_data_q_jump_routes.csv\"),\n",
    "        index_col = 0\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "wmata_schedule_gdf = (\n",
    "    gpd.GeoDataFrame(\n",
    "        wmata_schedule_dat, \n",
    "        geometry = gpd.points_from_xy(wmata_schedule_dat.stop_lon,wmata_schedule_dat.stop_lat),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    .to_crs(epsg=wmata_crs)\n",
    ")\n",
    "\n",
    "# Make Output Directory\n",
    "path_stop_summary = os.path.join(path_processed_data, \"stop_summary.parquet\")\n",
    "if not os.path.isdir(path_stop_summary):\n",
    "    os.mkdir(path_stop_summary)\n",
    "\n",
    "path_stop_index = os.path.join(path_processed_data, \"stop_index.parquet\")\n",
    "if not os.path.isdir(path_stop_index):\n",
    "    os.mkdir(path_stop_index)\n",
    "\n",
    "for analysis_route in analysis_routes:\n",
    "    print(\"*\" * 100)\n",
    "    print('Processing analysis route {}'.format(analysis_route))\n",
    "    for analysis_day in analysis_days:\n",
    "        print('Processing analysis route {} for {}...'.format(analysis_route,analysis_day))\n",
    "                \n",
    "        # Reload data\n",
    "        try:\n",
    "            rawnav_dat = (\n",
    "                wr.read_cleaned_rawnav(\n",
    "                   analysis_routes_ = analysis_route,\n",
    "                   analysis_days_ = analysis_day,\n",
    "                   path = os.path.join(path_processed_data, \"rawnav_data.parquet\")\n",
    "                )\n",
    "                .drop(columns=['blank', 'lat_raw', 'long_raw', 'sat_cnt'])\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)  # usually no data found or something similar\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "            rawnav_summary_dat = (\n",
    "                wr.read_cleaned_rawnav(\n",
    "                    analysis_routes_ = analysis_route,\n",
    "                    analysis_days_ = analysis_day,\n",
    "                    path = os.path.join(path_processed_data, \"rawnav_summary.parquet\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Subset Rawnav Data to Records Desired\n",
    "            rawnav_summary_dat = rawnav_summary_dat.query('not (run_duration_from_sec < 600 | dist_odom_mi < 2)')\n",
    "            \n",
    "            rawnav_summary_keys_col = rawnav_summary_dat[['filename', 'index_run_start']]\n",
    "            \n",
    "            rawnav_qjump_dat = rawnav_dat.merge(rawnav_summary_keys_col,\n",
    "                                                on=['filename', 'index_run_start'],\n",
    "                                                how='right')\n",
    "\n",
    "            rawnav_qjump_gdf = (\n",
    "                gpd.GeoDataFrame(\n",
    "                    rawnav_qjump_dat,\n",
    "                    geometry=gpd.points_from_xy(rawnav_qjump_dat.long, rawnav_qjump_dat.lat),\n",
    "                    crs='EPSG:4326'\n",
    "                )\n",
    "                .to_crs(epsg=wmata_crs)\n",
    "            )\n",
    "\n",
    "        stop_summary, stop_index = (\n",
    "            wr.merge_rawnav_wmata_schedule(\n",
    "                analysis_route_=analysis_route,\n",
    "                analysis_day_=analysis_day,\n",
    "                rawnav_dat_=rawnav_qjump_gdf,\n",
    "                rawnav_sum_dat_=rawnav_summary_dat,\n",
    "                wmata_schedule_dat_=wmata_schedule_gdf\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if type(stop_summary) == type(None):\n",
    "            print('No data on analysis route {} for {}'.format(analysis_route,analysis_day))\n",
    "            continue\n",
    "        \n",
    "        # Write Summary Table \n",
    "        shutil.rmtree(\n",
    "            os.path.join(\n",
    "                path_stop_summary,\n",
    "                \"route={}\".format(analysis_route),\n",
    "                \"wday={}\".format(analysis_day)\n",
    "            ),\n",
    "            ignore_errors=True\n",
    "        ) \n",
    "        \n",
    "        pq.write_to_dataset(\n",
    "            table=pa.Table.from_pandas(stop_summary),\n",
    "            root_path=path_stop_summary,\n",
    "            partition_cols=['route', 'wday']\n",
    "        )\n",
    "        \n",
    "        # Write Index Table\n",
    "        shutil.rmtree(\n",
    "            os.path.join(\n",
    "                path_stop_index,\n",
    "                \"route={}\".format(analysis_route),\n",
    "                \"wday={}\".format(analysis_day)\n",
    "            ),\n",
    "            ignore_errors=True\n",
    "        ) \n",
    "        \n",
    "        stop_index = wr.drop_geometry(stop_index)\n",
    "        \n",
    "        stop_index = stop_index.assign(wday=analysis_day)\n",
    "                \n",
    "        pq.write_to_dataset(\n",
    "            table=pa.Table.from_pandas(stop_index),\n",
    "            root_path=path_stop_index,\n",
    "            partition_cols=['route', 'wday']\n",
    "        )\n",
    "\n",
    "executionTime = str(datetime.now() - begin_time).split('.')[0]\n",
    "print(\n",
    "      \"Run Time Section Section 2: Read, analyze and summarize rawnav, WMATA schedule data : {}\"\n",
    "      .format(executionTime)\n",
    ")\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-819d6a07e6fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpartition_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'route'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wday'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_summary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# partition_keys = [df[col] for col in partition_cols]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rawnav\\lib\\site-packages\\pyarrow\\table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rawnav\\lib\\site-packages\\pyarrow\\pandas_compat.py\u001b[0m in \u001b[0;36mdataframe_to_arrays\u001b[1;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[0;32m    535\u001b[0m      \u001b[0mindex_columns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m      \u001b[0mcolumns_to_convert\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m      \u001b[0mconvert_fields\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_columns_to_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m                                                columns)\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rawnav\\lib\\site-packages\\pyarrow\\pandas_compat.py\u001b[0m in \u001b[0;36m_get_columns_to_convert\u001b[1;34m(df, schema, preserve_index, columns)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_columns_to_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_resolve_columns_of_interest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rawnav\\lib\\site-packages\\pyarrow\\pandas_compat.py\u001b[0m in \u001b[0;36m_resolve_columns_of_interest\u001b[1;34m(df, schema, columns)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "partition_cols = ['route', 'wday']\n",
    "df = pa.Table.from_pandas(stop_summary).to_pandas()\n",
    "# partition_keys = [df[col] for col in partition_cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rawnav)",
   "language": "python",
   "name": "rawnav"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
